{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "articles = pd.read_csv('articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Yashvardhan\n",
      "[nltk_data]     Sharma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>988839</th>\n",
       "      <td>[stocks, set, new, 52week, highs, friday, augu...</td>\n",
       "      <td>2018-08-06 13:02:00</td>\n",
       "      <td>PFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309834</th>\n",
       "      <td>[bofa, lowers, target, cognizant, $77, legisla...</td>\n",
       "      <td>2013-06-19 12:07:00</td>\n",
       "      <td>CTSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130454</th>\n",
       "      <td>[modulus, provider, highperformance, trading, ...</td>\n",
       "      <td>2019-10-18 15:45:00</td>\n",
       "      <td>BAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310901</th>\n",
       "      <td>[vermillion, inc, reports, q2, eps, $015, 15, ...</td>\n",
       "      <td>2014-08-14 16:22:00</td>\n",
       "      <td>VRML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194268</th>\n",
       "      <td>[synacor, reports, extension, search, ad, rela...</td>\n",
       "      <td>2018-05-31 08:38:00</td>\n",
       "      <td>SYNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343909</th>\n",
       "      <td>[jung, hak, son, joins, wilshire, bancorp, chi...</td>\n",
       "      <td>2013-09-09 08:01:00</td>\n",
       "      <td>WIBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549584</th>\n",
       "      <td>[einhorn, says, green, mountain, thesis, playi...</td>\n",
       "      <td>2013-11-21 12:38:00</td>\n",
       "      <td>GMCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735343</th>\n",
       "      <td>[macquarie, analyst, downgrades, union, pacifi...</td>\n",
       "      <td>2015-08-20 08:05:00</td>\n",
       "      <td>KSU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125060</th>\n",
       "      <td>[earnings, scheduled, june, 6, 2019]</td>\n",
       "      <td>2019-06-06 04:02:00</td>\n",
       "      <td>SIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906861</th>\n",
       "      <td>[hurricane, barry, left, mark, could, worse]</td>\n",
       "      <td>2019-07-16 10:43:00</td>\n",
       "      <td>NSC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  \\\n",
       "988839   [stocks, set, new, 52week, highs, friday, augu...   \n",
       "309834   [bofa, lowers, target, cognizant, $77, legisla...   \n",
       "130454   [modulus, provider, highperformance, trading, ...   \n",
       "1310901  [vermillion, inc, reports, q2, eps, $015, 15, ...   \n",
       "1194268  [synacor, reports, extension, search, ad, rela...   \n",
       "...                                                    ...   \n",
       "1343909  [jung, hak, son, joins, wilshire, bancorp, chi...   \n",
       "549584   [einhorn, says, green, mountain, thesis, playi...   \n",
       "735343   [macquarie, analyst, downgrades, union, pacifi...   \n",
       "1125060               [earnings, scheduled, june, 6, 2019]   \n",
       "906861        [hurricane, barry, left, mark, could, worse]   \n",
       "\n",
       "                       date ticker  \n",
       "988839  2018-08-06 13:02:00    PFE  \n",
       "309834  2013-06-19 12:07:00   CTSH  \n",
       "130454  2019-10-18 15:45:00    BAC  \n",
       "1310901 2014-08-14 16:22:00   VRML  \n",
       "1194268 2018-05-31 08:38:00   SYNC  \n",
       "...                     ...    ...  \n",
       "1343909 2013-09-09 08:01:00   WIBC  \n",
       "549584  2013-11-21 12:38:00   GMCR  \n",
       "735343  2015-08-20 08:05:00    KSU  \n",
       "1125060 2019-06-06 04:02:00    SIG  \n",
       "906861  2019-07-16 10:43:00    NSC  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from datetime import datetime as dt\n",
    "import pytz\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Credit to / help from https://saturncloud.io/blog/how-to-remove-stop-words-from-a-pandas-dataframe-using-python/\n",
    "def remove_stopwords(words_tokenized):\n",
    "    stop_words = set(stopwords.words('english'))  # List of english stopwords\n",
    "    return [word for word in words_tokenized if word not in stop_words] # Using list comprehension, only choose the words that aren't stopwords\n",
    "\n",
    "def convert_to_datetime(date_string):\n",
    "    converted_date = dt.strptime(date_string, '%Y-%m-%d %H:%M:%S%z')\n",
    "    converted_date = converted_date.replace(tzinfo=None)\n",
    "    return converted_date\n",
    "\n",
    "def preprocess(df, sample_size=None):\n",
    "    df = df.dropna()\n",
    "    # sample if specified\n",
    "    if sample_size:\n",
    "        df = df.sample(sample_size)\n",
    "    # remove uncessary index column\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    # change stock column name to ticker\n",
    "    df.rename(columns={'stock': 'ticker'}, inplace=True)\n",
    "    # convert headlines to lowercase\n",
    "    df['title'] = df['title'].str.lower()\n",
    "    # remove punctuation\n",
    "    df['title'] = df['title'].str.replace(r'[^a-zA-Z\\s$0-9]', '', regex=True)\n",
    "    # tokenize\n",
    "    df['title'] = df['title'].str.split() \n",
    "    # remove stopwords\n",
    "    df['title'] = df['title'].apply(remove_stopwords)\n",
    "    # convert to datetime object\n",
    "    df['date'] = df['date'].apply(convert_to_datetime)\n",
    "    return df\n",
    "\n",
    "articles = preprocess(articles, sample_size=1000)\n",
    "\n",
    "articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab Stock Returns\n",
    "\n",
    "Based on the time of the article published, we will retrieve two adjusted close prices of the stock and compute the corresponding return.\n",
    "\n",
    "If the time of the article is published before 4:00 P.M. (non-inclusive), then:\n",
    "1. The 'before' price will be the most recent (before the date) trading day's adjusted close price\n",
    "2. The 'after' price will be the most upcoming trading day's adjusted close price\n",
    "\n",
    "If the time of the article is published after 4:00 P.M., then:\n",
    "1. The 'before' price will be the same day's adjusted close price\n",
    "2. The 'after' priec will be the next day's adjusted close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_market_calendars as mcal\n",
    "from datetime import timedelta\n",
    "# The paramater forward is a boolean representing whether we are looking for the next valid trading day or the most recent trading day\n",
    "def getValidTradingCloseDate(date, forward=True):\n",
    "        nyse = mcal.get_calendar('NYSE')\n",
    "        if forward:\n",
    "            start_date = date\n",
    "            end_date = date+timedelta(days=15)\n",
    "        else:\n",
    "            start_date = date-timedelta(days=15)\n",
    "            nextTradingDay = nyse.valid_days(start_date=date , end_date=date + timedelta(days=15))\n",
    "            end_date = nextTradingDay[0]\n",
    "\n",
    "        validTradingDays = nyse.valid_days(start_date=start_date , end_date=end_date)\n",
    "\n",
    "        return validTradingDays.date[1] if forward else validTradingDays.date[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the yfinance data we need based on date.\n",
    "import yfinance as yf\n",
    "\n",
    "def retrieve_yfinance_data(row):\n",
    "    curr_date = row['date']\n",
    "    \n",
    "    eod = dt.strptime('16:00:00', '%H:%M:%S').time()\n",
    "    \n",
    "    if curr_date.time() > eod:\n",
    "        start_date = curr_date\n",
    "        end_date = getValidTradingCloseDate(start_date, forward=True)\n",
    "    else:\n",
    "        end_date = curr_date\n",
    "        start_date = getValidTradingCloseDate(end_date, forward=False)\n",
    "    \n",
    "        \n",
    "    start_date = start_date.strftime('%Y-%m-%d')\n",
    "    end_date = end_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(start_date, end_date)\n",
    "    \n",
    "    data = yf.download(row['ticker'], start=start_date, end=end_date)\n",
    "    if len(data) > 0:\n",
    "        returns = (data['Adj Close'][-1] - data['Adj Close'][0]) / data['Adj Close'][0]\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title     [stocks, set, new, 52week, highs, friday, augu...\n",
      "date                                    2018-08-06 13:02:00\n",
      "ticker                                                  PFE\n",
      "Name: 988839, dtype: object\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Start and end cannot both be tz-aware with different timezones",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2596\u001b[0m, in \u001b[0;36m_infer_tz_from_endpoints\u001b[1;34m(start, end, tz)\u001b[0m\n\u001b[0;32m   2595\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2596\u001b[0m     inferred_tz \u001b[39m=\u001b[39m timezones\u001b[39m.\u001b[39;49minfer_tzinfo(start, end)\n\u001b[0;32m   2597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   2598\u001b[0m     \u001b[39m# infer_tzinfo raises AssertionError if passed mismatched timezones\u001b[39;00m\n",
      "File \u001b[1;32mtimezones.pyx:369\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timezones.infer_tzinfo\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Inputs must both have the same timezone, None != UTC",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Yashvardhan Sharma\\OneDrive\\Documents\\Yash HW - College\\CS 584\\Project\\ArticleAlpha\\preprocess_data.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Yashvardhan%20Sharma/OneDrive/Documents/Yash%20HW%20-%20College/CS%20584/Project/ArticleAlpha/preprocess_data.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(articles\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Yashvardhan%20Sharma/OneDrive/Documents/Yash%20HW%20-%20College/CS%20584/Project/ArticleAlpha/preprocess_data.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m new_data \u001b[39m=\u001b[39m retrieve_yfinance_data(articles\u001b[39m.\u001b[39;49miloc[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Yashvardhan%20Sharma/OneDrive/Documents/Yash%20HW%20-%20College/CS%20584/Project/ArticleAlpha/preprocess_data.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# yf.download(\"AVAV\", start='2012-12-05', period='1d')\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Yashvardhan Sharma\\OneDrive\\Documents\\Yash HW - College\\CS 584\\Project\\ArticleAlpha\\preprocess_data.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yashvardhan%20Sharma/OneDrive/Documents/Yash%20HW%20-%20College/CS%20584/Project/ArticleAlpha/preprocess_data.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yashvardhan%20Sharma/OneDrive/Documents/Yash%20HW%20-%20College/CS%20584/Project/ArticleAlpha/preprocess_data.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     end_date \u001b[39m=\u001b[39m curr_date\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Yashvardhan%20Sharma/OneDrive/Documents/Yash%20HW%20-%20College/CS%20584/Project/ArticleAlpha/preprocess_data.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     start_date \u001b[39m=\u001b[39m getValidTradingCloseDate(end_date\u001b[39m.\u001b[39;49mdate(), forward\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yashvardhan%20Sharma/OneDrive/Documents/Yash%20HW%20-%20College/CS%20584/Project/ArticleAlpha/preprocess_data.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m start_date \u001b[39m=\u001b[39m start_date\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yashvardhan%20Sharma/OneDrive/Documents/Yash%20HW%20-%20College/CS%20584/Project/ArticleAlpha/preprocess_data.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m end_date \u001b[39m=\u001b[39m end_date\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Yashvardhan Sharma\\OneDrive\\Documents\\Yash HW - College\\CS 584\\Project\\ArticleAlpha\\preprocess_data.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yashvardhan%20Sharma/OneDrive/Documents/Yash%20HW%20-%20College/CS%20584/Project/ArticleAlpha/preprocess_data.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     nextTradingDay \u001b[39m=\u001b[39m nyse\u001b[39m.\u001b[39mvalid_days(start_date\u001b[39m=\u001b[39mdate , end_date\u001b[39m=\u001b[39mdate \u001b[39m+\u001b[39m timedelta(days\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yashvardhan%20Sharma/OneDrive/Documents/Yash%20HW%20-%20College/CS%20584/Project/ArticleAlpha/preprocess_data.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     end_date \u001b[39m=\u001b[39m nextTradingDay[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Yashvardhan%20Sharma/OneDrive/Documents/Yash%20HW%20-%20College/CS%20584/Project/ArticleAlpha/preprocess_data.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m validTradingDays \u001b[39m=\u001b[39m nyse\u001b[39m.\u001b[39;49mvalid_days(start_date\u001b[39m=\u001b[39;49mstart_date , end_date\u001b[39m=\u001b[39;49mend_date)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yashvardhan%20Sharma/OneDrive/Documents/Yash%20HW%20-%20College/CS%20584/Project/ArticleAlpha/preprocess_data.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mreturn\u001b[39;00m validTradingDays\u001b[39m.\u001b[39mdate[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m forward \u001b[39melse\u001b[39;00m validTradingDays\u001b[39m.\u001b[39mdate[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas_market_calendars\\calendars\\nyse.py:1092\u001b[0m, in \u001b[0;36mNYSEExchangeCalendar.valid_days\u001b[1;34m(self, start_date, end_date, tz)\u001b[0m\n\u001b[0;32m   1083\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalid_days\u001b[39m(\u001b[39mself\u001b[39m, start_date, end_date, tz\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUTC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m   1084\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m \u001b[39m    Get a DatetimeIndex of valid open business days.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[39m    :return: DatetimeIndex of valid business days\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1092\u001b[0m     trading_days \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mvalid_days(start_date, end_date, tz\u001b[39m=\u001b[39;49m tz)\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# Starting Monday Sept. 29, 1952, no more saturday trading days\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mif\u001b[39;00m tz \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: saturday_end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_saturday_end\u001b[39m.\u001b[39mtz_localize(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas_market_calendars\\market_calendar.py:498\u001b[0m, in \u001b[0;36mMarketCalendar.valid_days\u001b[1;34m(self, start_date, end_date, tz)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalid_days\u001b[39m(\u001b[39mself\u001b[39m, start_date, end_date, tz\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUTC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    490\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \u001b[39m    Get a DatetimeIndex of valid open business days.\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39m    :return: DatetimeIndex of valid business days\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 498\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39;49mdate_range(start_date, end_date, freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mholidays(), normalize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, tz\u001b[39m=\u001b[39;49mtz)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:1009\u001b[0m, in \u001b[0;36mdate_range\u001b[1;34m(start, end, periods, freq, tz, normalize, name, inclusive, unit, **kwargs)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[39mif\u001b[39;00m freq \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m com\u001b[39m.\u001b[39many_none(periods, start, end):\n\u001b[0;32m   1007\u001b[0m     freq \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mD\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1009\u001b[0m dtarr \u001b[39m=\u001b[39m DatetimeArray\u001b[39m.\u001b[39;49m_generate_range(\n\u001b[0;32m   1010\u001b[0m     start\u001b[39m=\u001b[39;49mstart,\n\u001b[0;32m   1011\u001b[0m     end\u001b[39m=\u001b[39;49mend,\n\u001b[0;32m   1012\u001b[0m     periods\u001b[39m=\u001b[39;49mperiods,\n\u001b[0;32m   1013\u001b[0m     freq\u001b[39m=\u001b[39;49mfreq,\n\u001b[0;32m   1014\u001b[0m     tz\u001b[39m=\u001b[39;49mtz,\n\u001b[0;32m   1015\u001b[0m     normalize\u001b[39m=\u001b[39;49mnormalize,\n\u001b[0;32m   1016\u001b[0m     inclusive\u001b[39m=\u001b[39;49minclusive,\n\u001b[0;32m   1017\u001b[0m     unit\u001b[39m=\u001b[39;49munit,\n\u001b[0;32m   1018\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[0;32m   1020\u001b[0m \u001b[39mreturn\u001b[39;00m DatetimeIndex\u001b[39m.\u001b[39m_simple_new(dtarr, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:428\u001b[0m, in \u001b[0;36mDatetimeArray._generate_range\u001b[1;34m(cls, start, end, periods, freq, tz, normalize, ambiguous, nonexistent, inclusive, unit)\u001b[0m\n\u001b[0;32m    426\u001b[0m left_inclusive, right_inclusive \u001b[39m=\u001b[39m validate_inclusive(inclusive)\n\u001b[0;32m    427\u001b[0m start, end \u001b[39m=\u001b[39m _maybe_normalize_endpoints(start, end, normalize)\n\u001b[1;32m--> 428\u001b[0m tz \u001b[39m=\u001b[39m _infer_tz_from_endpoints(start, end, tz)\n\u001b[0;32m    430\u001b[0m \u001b[39mif\u001b[39;00m tz \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    431\u001b[0m     \u001b[39m# Localize the start and end arguments\u001b[39;00m\n\u001b[0;32m    432\u001b[0m     start_tz \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m start \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m start\u001b[39m.\u001b[39mtz\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2599\u001b[0m, in \u001b[0;36m_infer_tz_from_endpoints\u001b[1;34m(start, end, tz)\u001b[0m\n\u001b[0;32m   2596\u001b[0m     inferred_tz \u001b[39m=\u001b[39m timezones\u001b[39m.\u001b[39minfer_tzinfo(start, end)\n\u001b[0;32m   2597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   2598\u001b[0m     \u001b[39m# infer_tzinfo raises AssertionError if passed mismatched timezones\u001b[39;00m\n\u001b[1;32m-> 2599\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   2600\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mStart and end cannot both be tz-aware with different timezones\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2601\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   2603\u001b[0m inferred_tz \u001b[39m=\u001b[39m timezones\u001b[39m.\u001b[39mmaybe_get_tz(inferred_tz)\n\u001b[0;32m   2604\u001b[0m tz \u001b[39m=\u001b[39m timezones\u001b[39m.\u001b[39mmaybe_get_tz(tz)\n",
      "\u001b[1;31mTypeError\u001b[0m: Start and end cannot both be tz-aware with different timezones"
     ]
    }
   ],
   "source": [
    "print(articles.iloc[0])\n",
    "new_data = retrieve_yfinance_data(articles.iloc[0])\n",
    "\n",
    "# yf.download(\"AVAV\", start='2012-12-05', period='1d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
