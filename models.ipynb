{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>returns</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219534</th>\n",
       "      <td>Benzinga’s Top Upgrades (SBNY, CCL, MPW, MA, F...</td>\n",
       "      <td>2010-05-21 08:27:00</td>\n",
       "      <td>CCL</td>\n",
       "      <td>0.013952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912659</th>\n",
       "      <td>Top Performing Industries For August 9, 2016</td>\n",
       "      <td>2016-08-09 10:54:00</td>\n",
       "      <td>NTL</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165581</th>\n",
       "      <td>Bridgeline DIgital Reports Q3 Loss $0.26 Vs Es...</td>\n",
       "      <td>2015-08-14 08:01:00</td>\n",
       "      <td>BLIN</td>\n",
       "      <td>-0.048276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355251</th>\n",
       "      <td>Earnings Scheduled For March 24, 2015</td>\n",
       "      <td>2015-03-24 04:04:00</td>\n",
       "      <td>WSCI</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362331</th>\n",
       "      <td>Puts Purchased on Dick's Sporting Goods (DKS)</td>\n",
       "      <td>2011-01-06 12:40:00</td>\n",
       "      <td>DKS</td>\n",
       "      <td>-0.045442</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236358</th>\n",
       "      <td>Standpoint Research Downgrades Tempur-pedic In...</td>\n",
       "      <td>2013-10-01 11:17:00</td>\n",
       "      <td>TPX</td>\n",
       "      <td>0.023658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370405</th>\n",
       "      <td>Sector Update: Utilities Leading, Consumer Goo...</td>\n",
       "      <td>2011-08-24 10:36:00</td>\n",
       "      <td>XLF</td>\n",
       "      <td>0.026678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90206</th>\n",
       "      <td>Aramark Acquires On-Demand Food Delivery Servi...</td>\n",
       "      <td>2019-08-06 06:44:00</td>\n",
       "      <td>ARMK</td>\n",
       "      <td>0.047018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342675</th>\n",
       "      <td>Wheeler Real Estate Investment Trust Responds ...</td>\n",
       "      <td>2018-03-16 04:19:00</td>\n",
       "      <td>WHLR</td>\n",
       "      <td>0.064220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940789</th>\n",
       "      <td>Olin Reports Q1 EPS $(0.23) vs. Est. $0.22, Re...</td>\n",
       "      <td>2016-05-02 17:40:00</td>\n",
       "      <td>OLN</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  \\\n",
       "219534   Benzinga’s Top Upgrades (SBNY, CCL, MPW, MA, F...   \n",
       "912659        Top Performing Industries For August 9, 2016   \n",
       "165581   Bridgeline DIgital Reports Q3 Loss $0.26 Vs Es...   \n",
       "1355251              Earnings Scheduled For March 24, 2015   \n",
       "362331       Puts Purchased on Dick's Sporting Goods (DKS)   \n",
       "...                                                    ...   \n",
       "1236358  Standpoint Research Downgrades Tempur-pedic In...   \n",
       "1370405  Sector Update: Utilities Leading, Consumer Goo...   \n",
       "90206    Aramark Acquires On-Demand Food Delivery Servi...   \n",
       "1342675  Wheeler Real Estate Investment Trust Responds ...   \n",
       "940789   Olin Reports Q1 EPS $(0.23) vs. Est. $0.22, Re...   \n",
       "\n",
       "                       date ticker   returns  sentiment  \n",
       "219534  2010-05-21 08:27:00    CCL  0.013952          1  \n",
       "912659  2016-08-09 10:54:00    NTL -0.010309          0  \n",
       "165581  2015-08-14 08:01:00   BLIN -0.048276          0  \n",
       "1355251 2015-03-24 04:04:00   WSCI  0.001757          2  \n",
       "362331  2011-01-06 12:40:00    DKS -0.045442          0  \n",
       "...                     ...    ...       ...        ...  \n",
       "1236358 2013-10-01 11:17:00    TPX  0.023658          1  \n",
       "1370405 2011-08-24 10:36:00    XLF  0.026678          1  \n",
       "90206   2019-08-06 06:44:00   ARMK  0.047018          1  \n",
       "1342675 2018-03-16 04:19:00   WHLR  0.064220          1  \n",
       "940789  2016-05-02 17:40:00    OLN  0.015110          1  \n",
       "\n",
       "[71 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_pickle('Data/small_test_set.pkl')\n",
    "# drop NaN\n",
    "dataset = dataset.dropna()\n",
    "# add a column that defines sentiment. sentiment is 0 if returns is < 0.01, 1 if returns is > 0.01 and 2 if returns is 0\n",
    "dataset['sentiment'] = dataset['returns'].apply(lambda x: 0 if x < -.01 else 1 if x > 0.01 else 2)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset into Train, Validation, and Test\n",
    "- Train (80%)\n",
    "- Test (10%)\n",
    "- Validation (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    x_train, x_test_and_val, y_train, y_test_and_val  = train_test_split(df['title'], df['returns'], random_state=42, test_size=0.2) # train set is 80%,\n",
    "    x_test, x_val, y_test, y_val = train_test_split(x_test_and_val, y_test_and_val, test_size=0.5, random_state=42) # test and val are 50% of the remaining 20% = 10%. \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = split(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def get_model_and_tokenizer(model_name, num_labels=3):\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name,num_labels=num_labels)\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "  return tokenizer, model\n",
    "\n",
    "bert_tokenizer, bert_model = get_model_and_tokenizer('bert-base-uncased')\n",
    "finbert_tokenizer, finbert_model = get_model_and_tokenizer('ProsusAI/finbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Samples</th>\n",
       "      <th>Number of Samples with Positive Returns</th>\n",
       "      <th>Number of Samples with No Returns</th>\n",
       "      <th>Number of Samples with Negative Returns</th>\n",
       "      <th>Minimum Number of Tokens</th>\n",
       "      <th>Maximum Number of Tokens</th>\n",
       "      <th>Mean Number of Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>235</td>\n",
       "      <td>70.053571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>128</td>\n",
       "      <td>73.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>232</td>\n",
       "      <td>98.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Number of Samples  Number of Samples with Positive Returns  \\\n",
       "Train                      56                                       29   \n",
       "Test                        7                                        3   \n",
       "Validation                  8                                        8   \n",
       "\n",
       "            Number of Samples with No Returns  \\\n",
       "Train                                       1   \n",
       "Test                                        1   \n",
       "Validation                                  0   \n",
       "\n",
       "            Number of Samples with Negative Returns  Minimum Number of Tokens  \\\n",
       "Train                                            26                        23   \n",
       "Test                                              3                        40   \n",
       "Validation                                        0                        45   \n",
       "\n",
       "            Maximum Number of Tokens  Mean Number of Tokens  \n",
       "Train                            235              70.053571  \n",
       "Test                             128              73.857143  \n",
       "Validation                       232              98.625000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze(titles, returns):\n",
    "    \n",
    "    tokenized_titles = bert_tokenizer(titles.tolist())['input_ids']\n",
    "\n",
    "    num_samples = len(tokenized_titles)\n",
    "    \n",
    "    num_pos = len(returns[returns > 0])\n",
    "    num_neg = len(returns[returns < 0])\n",
    "    num_zero = len(returns[returns == 0])\n",
    "\n",
    "    list_lengths = titles.apply(len)\n",
    "\n",
    "    # Find the size of the smallest/largest list\n",
    "    num_min_tokens = min(list_lengths)\n",
    "    num_max_tokens = max(list_lengths)\n",
    "    num_mean_tokens = list_lengths.mean()\n",
    "    \n",
    "    return {\"Number of Samples\":num_samples, \n",
    "            \"Number of Samples with Positive Returns\": num_pos,\n",
    "            \"Number of Samples with No Returns\": num_zero,\n",
    "            \"Number of Samples with Negative Returns\": num_neg,\n",
    "            \"Minimum Number of Tokens\": num_min_tokens, \n",
    "            \"Maximum Number of Tokens\":num_max_tokens, \n",
    "            \"Mean Number of Tokens\":num_mean_tokens}\n",
    "\n",
    "def df_for_analysis(train_analysis, test_analysis, validation_analysis):\n",
    "    df = pd.DataFrame([train_analysis, test_analysis, validation_analysis], index=['Train', 'Test', 'Validation'])\n",
    "    return df\n",
    "\n",
    "analysis_df = df_for_analysis(analyze(x_train, y_train), analyze(x_test,y_test), analyze(x_val, y_val))\n",
    "\n",
    "analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43661971830985913\n",
      "0.352112676056338\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def predict_article(model, tokenizer, sample):\n",
    "    inputs = tokenizer(sample, return_tensors='pt')\n",
    "    output = model(**inputs)\n",
    "    return output.logits\n",
    "\n",
    "def convert_to_sentiment_int(output, modelType):\n",
    "    if modelType == 'BERT':\n",
    "        return int(torch.argmax(output, dim=-1))\n",
    "    elif modelType == 'FinBERT':\n",
    "        result = int(torch.argmax(output, dim=-1))\n",
    "        # if 0, return 1, if 1, return 0, if 2, return 2. why? finbert flips 0 and 1. 0 is positive, 1 is negative. we want the opposite. \n",
    "        # 2 would be neutral. \n",
    "        return 1 if result == 0 else 0 if result == 1 else 2\n",
    "\n",
    "# now given a dataframe of samples, we can evaluate the model on each sample and return the results\n",
    "def predict_articles(model, tokenizer, df, modelType):\n",
    "    numCorrect = 0\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # 0 if negative, 1 if positive, 2 if neutral\n",
    "        ground_truth = row['sentiment'] \n",
    "        model_output = predict_article(model, tokenizer, row['title'])\n",
    "        prediction = convert_to_sentiment_int(model_output, modelType)\n",
    "        numCorrect+=1 if ground_truth == prediction else 0\n",
    "\n",
    "    accuracy = numCorrect / len(df)\n",
    "    return accuracy\n",
    "\n",
    "bert_accuracy = predict_articles(bert_model, bert_tokenizer, dataset, 'BERT') # this only produces 2 classes. we need 3.\n",
    "finbert_accuracy = predict_articles(finbert_model, finbert_tokenizer, dataset, 'FinBERT')\n",
    "\n",
    "print(finbert_accuracy)\n",
    "print(bert_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finbert Model Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
