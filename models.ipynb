{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from transformers import AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "These function will be used throughout the code to facilitate training/testing/analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(encodings, labels, batch_size):\n",
    "    lst2arr = lambda lst: np.array(lst)[np.newaxis, :]\n",
    "\n",
    "    input_ids  = torch.tensor(encodings['input_ids'])\n",
    "    token_type_ids = torch.tensor(encodings['token_type_ids'])\n",
    "    attention_masks = torch.tensor(encodings['attention_mask'])\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    dataset = TensorDataset(input_ids, attention_masks, labels, token_type_ids)\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = None\n",
    "    true_labels = None\n",
    "    for batch in tqdm(dataloader, total = len(dataloader)):\n",
    "        input_ids, attention_masks, labels, token_type_ids = [b.to(device) for b in batch]\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids)\n",
    "            output_np = outputs.logits.detach().cpu().numpy()\n",
    "            true_label = labels.cpu().numpy()\n",
    "\n",
    "            if predictions is None:\n",
    "                predictions = output_np\n",
    "            else:\n",
    "                predictions = np.append(predictions, output_np, axis=0)\n",
    "            if true_labels is None:\n",
    "                true_labels = true_label\n",
    "            else:\n",
    "                true_labels = np.append(true_labels, true_label, axis=0)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    true_labels = np.argmax(true_labels, axis=1)\n",
    "\n",
    "    correct = np.sum(predictions == true_labels)\n",
    "    total = len(predictions)\n",
    "    accuracy = correct / total\n",
    "    return predictions, true_labels, accuracy\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    x_train, x_test_and_val, y_train, y_test_and_val  = train_test_split(df['title'], df['sentiment'], random_state=42, test_size=0.2) # train set is 80%,\n",
    "    x_test, x_val, y_test, y_val = train_test_split(x_test_and_val, y_test_and_val, test_size=0.5, random_state=42) # test and val are 50% of the remaining 20% = 10%. \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle('Data/test_set.pkl')\n",
    "# drop NaN\n",
    "dataset = dataset.dropna()\n",
    "# add a column that defines sentiment. sentiment is 0 if returns is < -0.01, 1 if returns is > 0.01 and 2 if returns is 0\n",
    "dataset['sentiment'] = dataset['returns'].apply(lambda x: 0 if x < -.01 else 1 if x > 0.01 else 2)\n",
    "\n",
    "# dataset = dataset.sample(5000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset into Train, Validation, and Test\n",
    "- Train (80%)\n",
    "- Test (10%)\n",
    "- Validation (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = split(dataset)\n",
    "\n",
    "train_tokenized = bert_tokenizer(x_train.to_list(), padding=True)\n",
    "val_tokenized = bert_tokenizer(x_val.to_list(), padding=True)\n",
    "test_tokenized = bert_tokenizer(x_test.to_list(), padding=True)\n",
    "\n",
    "label_encoder = OneHotEncoder()\n",
    "train_labels = label_encoder.fit_transform(y_train.to_numpy().reshape(-1,1))\n",
    "val_labels =  label_encoder.transform(y_val.to_numpy().reshape(-1,1))\n",
    "test_labels =  label_encoder.transform(y_test.to_numpy().reshape(-1,1))\n",
    "\n",
    "if type(train_labels) == scipy.sparse.csr_matrix:\n",
    "        train_labels = train_labels.toarray()\n",
    "\n",
    "if type(val_labels) == scipy.sparse.csr_matrix:\n",
    "        val_labels = val_labels.toarray()\n",
    "\n",
    "if type(test_labels) == scipy.sparse.csr_matrix:\n",
    "        test_labels = test_labels.toarray()\n",
    "\n",
    "train_dataloader = get_dataloader(train_tokenized, train_labels, batch_size)\n",
    "val_dataloader = get_dataloader(val_tokenized, val_labels, batch_size)\n",
    "test_dataloader = get_dataloader(test_tokenized, test_labels, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Samples</th>\n",
       "      <th>Number of Samples with Meaningful Gain</th>\n",
       "      <th>Number of Samples with Small movement</th>\n",
       "      <th>Number of Samples with Meaningful loss</th>\n",
       "      <th>Minimum Number of Tokens</th>\n",
       "      <th>Maximum Number of Tokens</th>\n",
       "      <th>Mean Number of Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>55148</td>\n",
       "      <td>19313</td>\n",
       "      <td>18786</td>\n",
       "      <td>17049</td>\n",
       "      <td>3</td>\n",
       "      <td>458</td>\n",
       "      <td>74.550863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>6893</td>\n",
       "      <td>2432</td>\n",
       "      <td>2312</td>\n",
       "      <td>2149</td>\n",
       "      <td>13</td>\n",
       "      <td>390</td>\n",
       "      <td>74.484404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <td>6894</td>\n",
       "      <td>2419</td>\n",
       "      <td>2353</td>\n",
       "      <td>2122</td>\n",
       "      <td>9</td>\n",
       "      <td>401</td>\n",
       "      <td>73.311285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Number of Samples  Number of Samples with Meaningful Gain  \\\n",
       "Train                   55148                                   19313   \n",
       "Test                     6893                                    2432   \n",
       "Validation               6894                                    2419   \n",
       "\n",
       "            Number of Samples with Small movement  \\\n",
       "Train                                       18786   \n",
       "Test                                         2312   \n",
       "Validation                                   2353   \n",
       "\n",
       "            Number of Samples with Meaningful loss  Minimum Number of Tokens  \\\n",
       "Train                                        17049                         3   \n",
       "Test                                          2149                        13   \n",
       "Validation                                    2122                         9   \n",
       "\n",
       "            Maximum Number of Tokens  Mean Number of Tokens  \n",
       "Train                            458              74.550863  \n",
       "Test                             390              74.484404  \n",
       "Validation                       401              73.311285  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze(tokenized_input, output):\n",
    "\n",
    "    num_samples = len(tokenized_input)\n",
    "    \n",
    "    num_pos = len(output[output == 1])\n",
    "    num_neg = len(output[output == 0])\n",
    "    num_zero =  len(output[output == 2])\n",
    "\n",
    "    list_lengths = tokenized_input.apply(len)\n",
    "\n",
    "    # Find the size of the smallest/largest list\n",
    "    num_min_tokens = min(list_lengths)\n",
    "    num_max_tokens = max(list_lengths)\n",
    "    num_mean_tokens = list_lengths.mean()\n",
    "    \n",
    "    return {\"Number of Samples\":num_samples, \n",
    "            \"Number of Samples with Meaningful Gain\": num_pos,\n",
    "            \"Number of Samples with Small movement\": num_zero,\n",
    "            \"Number of Samples with Meaningful loss\": num_neg,\n",
    "            \"Minimum Number of Tokens\": num_min_tokens, \n",
    "            \"Maximum Number of Tokens\":num_max_tokens, \n",
    "            \"Mean Number of Tokens\":num_mean_tokens}\n",
    "\n",
    "def df_for_analysis(train_analysis, test_analysis, validation_analysis):\n",
    "    df = pd.DataFrame([train_analysis, test_analysis, validation_analysis], index=['Train', 'Test', 'Validation'])\n",
    "    return df\n",
    "\n",
    "analysis_df = df_for_analysis(analyze(x_train, y_train), analyze(x_test,y_test), analyze(x_val, y_val))\n",
    "\n",
    "analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 20\n",
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yashvardhan Sharma\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "criterion = BCEWithLogitsLoss()\n",
    "optimizer = AdamW(bert_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1724/1724 [08:33<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6296447862489213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:18<00:00, 11.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.4522773426167682\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1724/1724 [08:25<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6066501916957566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:18<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.4757760371337395\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1724/1724 [08:22<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5944582069811515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:18<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.4804177545691906\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1724/1724 [08:16<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5884585657026608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:18<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.48549463301421525\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1724/1724 [08:19<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.584088495027663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:19<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.4911517261386713\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1724/1724 [08:16<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5802281611573796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:18<00:00, 11.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.49318247751668115\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1724/1724 [08:25<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5769221023446267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:18<00:00, 11.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.4934725848563969\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1724/1724 [08:18<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5736419084528704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:18<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.4960835509138381\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1724/1724 [08:16<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5695278284084208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:18<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.49637365825355384\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1724/1724 [08:20<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.566874998265372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:18<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.4960835509138381\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 199/1724 [00:58<07:30,  3.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m), batch_labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 16\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m train_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     19\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\Yashvardhan Sharma\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yashvardhan Sharma\\anaconda3\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Yashvardhan Sharma\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:467\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;66;03m# In-place operations to update the averages at the same time\u001b[39;00m\n\u001b[0;32m    466\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta1))\n\u001b[1;32m--> 467\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    468\u001b[0m denom \u001b[38;5;241m=\u001b[39m exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m.\u001b[39madd_(group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    470\u001b[0m step_size \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    bert_model.train()\n",
    "    train_loss, train_step = 0, 0\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    \n",
    "    for batch in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "        bert_model.zero_grad()\n",
    "        batch_input_ids, batch_attention_mask, batch_labels, batch_token_type_ids = [b.to(device) for b in batch]\n",
    "\n",
    "        output = bert_model(input_ids=batch_input_ids, attention_mask=batch_attention_mask, token_type_ids=batch_token_type_ids)\n",
    "        logits = output[0]\n",
    "        loss = criterion(logits.view(-1, 3), batch_labels.view(-1,3))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_step += 1\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    \n",
    "\n",
    "    print(f\"Train loss: {train_loss/train_step}\")\n",
    "    _, _, eval_acc = evaluate_model(bert_model, val_dataloader)\n",
    "    print(f\"Eval accuracy: {eval_acc}\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:20<00:00, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49064268098070507\n",
      "[1 2 0 ... 2 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions, true_labels, acc = evaluate_model(bert_model, test_dataloader)\n",
    "print(acc)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>44.47341</td>\n",
       "      <td>50.686005</td>\n",
       "      <td>50.990099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>50.56313</td>\n",
       "      <td>48.426966</td>\n",
       "      <td>48.738170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>39.69288</td>\n",
       "      <td>53.166118</td>\n",
       "      <td>53.460208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Negative   Positive    Neutral\n",
       "F1 Score   44.47341  50.686005  50.990099\n",
       "Precision  50.56313  48.426966  48.738170\n",
       "Recall     39.69288  53.166118  53.460208"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "bert_f1_score = f1_score(true_labels, predictions, average=None)\n",
    "bert_precision = precision_score(true_labels, predictions, average=None)\n",
    "bert_recall = recall_score(true_labels, predictions, average=None)\n",
    "bert_accuracy = accuracy_score(true_labels, predictions)\n",
    "#Convert values to percentages\n",
    "bert_f1_score = [i * 100 for i in bert_f1_score]\n",
    "bert_precision = [i * 100 for i in bert_precision]\n",
    "bert_recall = [i * 100 for i in bert_recall]\n",
    "pd.DataFrame([bert_f1_score, bert_precision, bert_recall], columns=['Negative', 'Positive', 'Neutral'], index=['F1 Score', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def predict_article(model, tokenizer, sample):\n",
    "    inputs = tokenizer(sample, return_tensors='pt')\n",
    "    inputs.to(\"cuda\")\n",
    "    output = model(**inputs)\n",
    "    return output.logits\n",
    "\n",
    "def convert_to_sentiment_int(output, modelType):\n",
    "    if modelType == 'BERT':\n",
    "        return int(torch.argmax(output, dim=-1))\n",
    "    elif modelType == 'FinBERT':\n",
    "        result = int(torch.argmax(output, dim=-1))\n",
    "        # if 0, return 1, if 1, return 0, if 2, return 2. why? finbert flips 0 and 1. 0 is positive, 1 is negative. we want the opposite. \n",
    "        # 2 would be neutral. \n",
    "        return 1 if result == 0 else 0 if result == 1 else 2\n",
    "\n",
    "# now given a dataframe of samples, we can evaluate the model on each sample and return the results\n",
    "def predict_articles(model, tokenizer, df, modelType):\n",
    "    numCorrect = 0\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        \n",
    "        # 0 if negative, 1 if positive, 2 if neutral\n",
    "        ground_truth = row['sentiment']\n",
    "        model_output = predict_article(model, tokenizer, row['title'])\n",
    "        prediction = convert_to_sentiment_int(model_output, modelType)\n",
    "        numCorrect+=1 if ground_truth == prediction else 0\n",
    "\n",
    "    accuracy = numCorrect / len(df)\n",
    "    return accuracy\n",
    "\n",
    "#bert_accuracy = predict_articles(bert_model, bert_tokenizer, dataset, 'BERT') # this only produces 2 classes. we need 3.\n",
    "#finbert_accuracy = predict_articles(finbert_model, finbert_tokenizer, dataset, 'FinBERT')\n",
    "\n",
    "#print(finbert_accuracy)\n",
    "print(bert_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert_accuracy = predict_articles(finbert_model, finbert_tokenizer, dataset, 'FinBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finbert Model Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
