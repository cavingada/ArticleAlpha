{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>returns</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>821831</th>\n",
       "      <td>Bank of America Reinstates Coverage on 3M at B...</td>\n",
       "      <td>2012-09-13 16:09:00</td>\n",
       "      <td>MMM</td>\n",
       "      <td>0.020856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384459</th>\n",
       "      <td>Does Yelp Need Help?</td>\n",
       "      <td>2015-04-30 14:04:00</td>\n",
       "      <td>YELP</td>\n",
       "      <td>-0.231864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684717</th>\n",
       "      <td>Morning Earnings Recap: The Biggest Reports Fr...</td>\n",
       "      <td>2019-01-25 06:40:00</td>\n",
       "      <td>JBLU</td>\n",
       "      <td>-0.022627</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16283</th>\n",
       "      <td>20 Healthcare Stocks Moving In Monday's Pre-Ma...</td>\n",
       "      <td>2020-03-16 08:32:00</td>\n",
       "      <td>ACST</td>\n",
       "      <td>-0.096774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226930</th>\n",
       "      <td>Start Your Engines: Global X Introduces An Aut...</td>\n",
       "      <td>2011-05-19 13:12:00</td>\n",
       "      <td>TM</td>\n",
       "      <td>-0.008478</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365170</th>\n",
       "      <td>Bank of America Downgrades Dollar Tree, Inc. t...</td>\n",
       "      <td>2014-07-28 14:14:00</td>\n",
       "      <td>DLTR</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877871</th>\n",
       "      <td>Option Alert: NCR Mar16 26.0 Puts Sweep: 1297 ...</td>\n",
       "      <td>2016-03-04 12:04:00</td>\n",
       "      <td>NCR</td>\n",
       "      <td>-0.023348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005885</th>\n",
       "      <td>Protalix BioTherapeutics Trading Significantly...</td>\n",
       "      <td>2011-02-25 09:59:00</td>\n",
       "      <td>PLX</td>\n",
       "      <td>-0.184829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116080</th>\n",
       "      <td>Seattle Genetics and Bristol-Myers Squibb Anno...</td>\n",
       "      <td>2015-12-23 08:01:00</td>\n",
       "      <td>SGEN</td>\n",
       "      <td>0.033404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136494</th>\n",
       "      <td>UPDATE: Jefferies Downgrades U.S. Silica Holdi...</td>\n",
       "      <td>2013-01-10 08:10:00</td>\n",
       "      <td>SLCA</td>\n",
       "      <td>-0.057262</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68935 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  \\\n",
       "821831   Bank of America Reinstates Coverage on 3M at B...   \n",
       "1384459                               Does Yelp Need Help?   \n",
       "684717   Morning Earnings Recap: The Biggest Reports Fr...   \n",
       "16283    20 Healthcare Stocks Moving In Monday's Pre-Ma...   \n",
       "1226930  Start Your Engines: Global X Introduces An Aut...   \n",
       "...                                                    ...   \n",
       "365170   Bank of America Downgrades Dollar Tree, Inc. t...   \n",
       "877871   Option Alert: NCR Mar16 26.0 Puts Sweep: 1297 ...   \n",
       "1005885  Protalix BioTherapeutics Trading Significantly...   \n",
       "1116080  Seattle Genetics and Bristol-Myers Squibb Anno...   \n",
       "1136494  UPDATE: Jefferies Downgrades U.S. Silica Holdi...   \n",
       "\n",
       "                       date ticker   returns  sentiment  \n",
       "821831  2012-09-13 16:09:00    MMM  0.020856          1  \n",
       "1384459 2015-04-30 14:04:00   YELP -0.231864          0  \n",
       "684717  2019-01-25 06:40:00   JBLU -0.022627          0  \n",
       "16283   2020-03-16 08:32:00   ACST -0.096774          0  \n",
       "1226930 2011-05-19 13:12:00     TM -0.008478          2  \n",
       "...                     ...    ...       ...        ...  \n",
       "365170  2014-07-28 14:14:00   DLTR  0.011988          1  \n",
       "877871  2016-03-04 12:04:00    NCR -0.023348          0  \n",
       "1005885 2011-02-25 09:59:00    PLX -0.184829          0  \n",
       "1116080 2015-12-23 08:01:00   SGEN  0.033404          1  \n",
       "1136494 2013-01-10 08:10:00   SLCA -0.057262          0  \n",
       "\n",
       "[68935 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_pickle('Data/test_set.pkl')\n",
    "# drop NaN\n",
    "dataset = dataset.dropna()\n",
    "# add a column that defines sentiment. sentiment is 0 if returns is < 0.01, 1 if returns is > 0.01 and 2 if returns is 0\n",
    "dataset['sentiment'] = dataset['returns'].apply(lambda x: 0 if x < -0.01 else 1 if x > 0.01 else 2)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset into Train, Validation, and Test\n",
    "- Train (80%)\n",
    "- Test (10%)\n",
    "- Validation (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    x_train, x_test_and_val, y_train, y_test_and_val  = train_test_split(df['title'], df['sentiment'], random_state=42, test_size=0.2) # train set is 80%,\n",
    "    x_test, x_val, y_test, y_val = train_test_split(x_test_and_val, y_test_and_val, test_size=0.5, random_state=42) # test and val are 50% of the remaining 20% = 10%. \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = split(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def get_model_and_tokenizer(model_name, num_labels=3):\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name,num_labels=num_labels)\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "  model.to(device)\n",
    "  return tokenizer, model\n",
    "\n",
    "bert_tokenizer, bert_model = get_model_and_tokenizer('bert-base-uncased')\n",
    "finbert_tokenizer, finbert_model = get_model_and_tokenizer('ProsusAI/finbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Samples</th>\n",
       "      <th>Number of Samples with Positive Returns</th>\n",
       "      <th>Number of Samples with No Returns</th>\n",
       "      <th>Number of Samples with Negative Returns</th>\n",
       "      <th>Minimum Number of Tokens</th>\n",
       "      <th>Maximum Number of Tokens</th>\n",
       "      <th>Mean Number of Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>55148</td>\n",
       "      <td>28705</td>\n",
       "      <td>712</td>\n",
       "      <td>25731</td>\n",
       "      <td>3</td>\n",
       "      <td>458</td>\n",
       "      <td>74.550863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>6893</td>\n",
       "      <td>3544</td>\n",
       "      <td>76</td>\n",
       "      <td>3273</td>\n",
       "      <td>13</td>\n",
       "      <td>390</td>\n",
       "      <td>74.484404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <td>6894</td>\n",
       "      <td>3603</td>\n",
       "      <td>70</td>\n",
       "      <td>3221</td>\n",
       "      <td>9</td>\n",
       "      <td>401</td>\n",
       "      <td>73.311285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Number of Samples  Number of Samples with Positive Returns  \\\n",
       "Train                   55148                                    28705   \n",
       "Test                     6893                                     3544   \n",
       "Validation               6894                                     3603   \n",
       "\n",
       "            Number of Samples with No Returns  \\\n",
       "Train                                     712   \n",
       "Test                                       76   \n",
       "Validation                                 70   \n",
       "\n",
       "            Number of Samples with Negative Returns  Minimum Number of Tokens  \\\n",
       "Train                                         25731                         3   \n",
       "Test                                           3273                        13   \n",
       "Validation                                     3221                         9   \n",
       "\n",
       "            Maximum Number of Tokens  Mean Number of Tokens  \n",
       "Train                            458              74.550863  \n",
       "Test                             390              74.484404  \n",
       "Validation                       401              73.311285  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze(titles, returns):\n",
    "    \n",
    "    tokenized_titles = bert_tokenizer(titles.tolist())['input_ids']\n",
    "\n",
    "    num_samples = len(tokenized_titles)\n",
    "    \n",
    "    num_pos = len(returns[returns > 0])\n",
    "    num_neg = len(returns[returns < 0])\n",
    "    num_zero = len(returns[returns == 0])\n",
    "\n",
    "    list_lengths = titles.apply(len)\n",
    "\n",
    "    # Find the size of the smallest/largest list\n",
    "    num_min_tokens = min(list_lengths)\n",
    "    num_max_tokens = max(list_lengths)\n",
    "    num_mean_tokens = list_lengths.mean()\n",
    "    \n",
    "    return {\"Number of Samples\":num_samples, \n",
    "            \"Number of Samples with Positive Returns\": num_pos,\n",
    "            \"Number of Samples with No Returns\": num_zero,\n",
    "            \"Number of Samples with Negative Returns\": num_neg,\n",
    "            \"Minimum Number of Tokens\": num_min_tokens, \n",
    "            \"Maximum Number of Tokens\":num_max_tokens, \n",
    "            \"Mean Number of Tokens\":num_mean_tokens}\n",
    "\n",
    "def df_for_analysis(train_analysis, test_analysis, validation_analysis):\n",
    "    df = pd.DataFrame([train_analysis, test_analysis, validation_analysis], index=['Train', 'Test', 'Validation'])\n",
    "    return df\n",
    "\n",
    "analysis_df = df_for_analysis(analyze(x_train, y_train), analyze(x_test,y_test), analyze(x_val, y_val))\n",
    "\n",
    "analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     title   returns\n",
      "959717   Pandora Shares Up 7.8% Following Q1 Earnings, ...  0.198261\n",
      "383482                    Danger Zone: Williams Companies  -0.004049\n",
      "545370   How to Profit from Gold's Current Price Instab...  0.000862\n",
      "32172                   Earnings Scheduled For May 9, 2017  0.020625\n",
      "666327   UPDATE: Goldman Sachs Resumes Intrepid Potash ... -0.004842\n",
      "...                                                    ...       ...\n",
      "955605   OpenText Signs Definitive Agreement to Acquire...  0.090012\n",
      "471970   FuelCell Energy Shares Fall Upon Earnings Repo...  0.045662\n",
      "1150330  Wall Street's M&A Chatter From June 20: Calpin...  0.006003\n",
      "1230404  Bank of America Maintains Underperform on Tand... -0.047782\n",
      "1164438       Top Narrow Based Indexes For January 3, 2013  0.479609\n",
      "\n",
      "[6893 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6893 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sentiment'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Yashvardhan Sharma\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Yashvardhan Sharma\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Yashvardhan Sharma\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sentiment'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([x_test, y_test], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_df)\n\u001b[1;32m---> 53\u001b[0m finbert_accuracy, fin_pos, fin_neg, fin_neut, true_labels, predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_articles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinbert_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinbert_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFinBERT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(finbert_accuracy, fin_pos, fin_neg, fin_neut)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# print(bert_accuracy)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 27\u001b[0m, in \u001b[0;36mpredict_articles\u001b[1;34m(model, tokenizer, df, modelType)\u001b[0m\n\u001b[0;32m     23\u001b[0m numNeut \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m tqdm(df\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     25\u001b[0m     \n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# 0 if negative, 1 if positive, 2 if neutral\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     ground_truth \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentiment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     28\u001b[0m     true_labels\u001b[38;5;241m.\u001b[39mappend(ground_truth)\n\u001b[0;32m     29\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m predict_article(model, tokenizer, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Yashvardhan Sharma\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yashvardhan Sharma\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\Yashvardhan Sharma\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sentiment'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def predict_article(model, tokenizer, sample):\n",
    "    inputs = tokenizer(sample, return_tensors='pt').to(device)\n",
    "    output = model(**inputs)\n",
    "    return output.logits\n",
    "\n",
    "def convert_to_sentiment_int(output, modelType):\n",
    "    if modelType == 'BERT':\n",
    "        return int(torch.argmax(output, dim=-1))\n",
    "    elif modelType == 'FinBERT':\n",
    "        result = int(torch.argmax(output, dim=-1))\n",
    "        # if 0, return 1, if 1, return 0, if 2, return 2. why? finbert flips 0 and 1. 0 is positive, 1 is negative. we want the opposite. \n",
    "        # 2 would be neutral. \n",
    "        return 1 if result == 0 else 0 if result == 1 else 2\n",
    "\n",
    "# now given a dataframe of samples, we can evaluate the model on each sample and return the results\n",
    "def predict_articles(model, tokenizer, df, modelType):\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    numCorrect = 0\n",
    "    numPos = 0\n",
    "    numNeg = 0\n",
    "    numNeut = 0\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        \n",
    "        # 0 if negative, 1 if positive, 2 if neutral\n",
    "        ground_truth = row['sentiment']\n",
    "        true_labels.append(ground_truth)\n",
    "        model_output = predict_article(model, tokenizer, row['title'])\n",
    "        prediction = convert_to_sentiment_int(model_output, modelType)\n",
    "        predictions.append(prediction)\n",
    "        numCorrect+=1 if ground_truth == prediction else 0\n",
    "        if ground_truth == prediction:\n",
    "            if prediction == 0:\n",
    "                numNeg+=1\n",
    "            elif prediction == 1:\n",
    "                numPos+=1\n",
    "            else:\n",
    "                numNeut+=1\n",
    "        \n",
    "    accuracy = numCorrect / len(df)\n",
    "    acc_pos = numPos / len(df[df['sentiment'] == 1])\n",
    "    acc_neg = numNeg / len(df[df['sentiment'] == 0])\n",
    "    acc_neut = numNeut / len(df[df['sentiment'] == 2])\n",
    "    \n",
    "    \n",
    "    return accuracy, acc_pos, acc_neg, acc_neut, true_labels, predictions\n",
    "\n",
    "# bert_accuracy = predict_articles(bert_model, bert_tokenizer, dataset, 'BERT') # this only produces 2 classes. we need 3.\n",
    "#combine x_test and y_test to make a dataframe\n",
    "test_df = pd.concat([x_test, y_test], axis=1)\n",
    "finbert_accuracy, fin_pos, fin_neg, fin_neut, true_labels, predictions = predict_articles(finbert_model, finbert_tokenizer, test_df, 'FinBERT')\n",
    "\n",
    "print(finbert_accuracy, fin_pos, fin_neg, fin_neut)\n",
    "# print(bert_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>15.284298</td>\n",
       "      <td>11.777342</td>\n",
       "      <td>66.071172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>9.082455</td>\n",
       "      <td>6.931999</td>\n",
       "      <td>92.849714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>48.190789</td>\n",
       "      <td>39.125039</td>\n",
       "      <td>51.281274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Negative   Positive    Neutral\n",
       "F1 Score   15.284298  11.777342  66.071172\n",
       "Precision   9.082455   6.931999  92.849714\n",
       "Recall     48.190789  39.125039  51.281274"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "finbert_f1_score = f1_score(true_labels, predictions, average=None)\n",
    "finbert_precision = precision_score(true_labels, predictions, average=None)\n",
    "finbert_recall = recall_score(true_labels, predictions, average=None)\n",
    "finbert_accuracy = accuracy_score(true_labels, predictions)\n",
    "#Convert values to percentages\n",
    "finbert_f1_score = [i * 100 for i in finbert_f1_score]\n",
    "finbert_precision = [i * 100 for i in finbert_precision]\n",
    "finbert_recall = [i * 100 for i in finbert_recall]\n",
    "pd.DataFrame([finbert_f1_score, finbert_precision, finbert_recall], columns=['Negative', 'Positive', 'Neutral'], index=['F1 Score', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digital Realty Trust, Inc. (DLR) to Buy 3 Datacenters for $375 mln\n",
      "0.01114718873943259\n",
      "2\n",
      "2\n",
      "\n",
      "\n",
      "Tandy Leather Factory, Inc. Reports May 2016 Sales Up 3% YoY, Retail SSS Up 5%, International SSS Down 5%\n",
      "-0.0013441167748555053\n",
      "2\n",
      "1\n",
      "\n",
      "\n",
      "Benchmark Maintains Buy on Coherent, Raises Price Target to $175\n",
      "-0.009290979313895477\n",
      "2\n",
      "1\n",
      "\n",
      "\n",
      "20 Biggest Mid-Day Gainers For Thursday\n",
      "0.035944573528740524\n",
      "2\n",
      "2\n",
      "\n",
      "\n",
      "7 Stocks To Watch For May 12, 2017\n",
      "-0.06435013186138398\n",
      "2\n",
      "2\n",
      "\n",
      "\n",
      "Brean Capital Reviews 3D Systems' Downward Spiral\n",
      "-0.07161215161117378\n",
      "2\n",
      "0\n",
      "\n",
      "\n",
      "UPDATE: RE/MAX Says 'Special Committee's investigation did not identify any matters requiring adjustments to the Company's previously issued financial statements'\n",
      "0.08721496721188436\n",
      "2\n",
      "2\n",
      "\n",
      "\n",
      "More Earnings And A Fed Decision In Week Four Of The WeTrader Competition\n",
      "0.019520641335001022\n",
      "2\n",
      "2\n",
      "\n",
      "\n",
      "Powell Industries Reports Q2 Adj. EPS $0.17 vs $0.09 Est., Sales $170.2M vs $156.7M Est.; Sees FY15 Sales $625M-$675M vs $650M Est.\n",
      "0.07505350915820078\n",
      "2\n",
      "1\n",
      "\n",
      "\n",
      "CRT Capital Initiates Coverage on The Children's Place Retail Stores, Inc. at Fairly Valued, Announces $52.00 PT\n",
      "-0.013277202898177399\n",
      "2\n",
      "2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_data = dataset.sample(10)\n",
    "for index, row in temp_data.iterrows():\n",
    "    print(row['title'])\n",
    "    print(row['returns'])\n",
    "    print(row['sentiment'])\n",
    "    print(convert_to_sentiment_int(predict_article(finbert_model, finbert_tokenizer, row['title']), 'FinBERT'))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finbert Model Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
